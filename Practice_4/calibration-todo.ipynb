{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_kw = dict(bins=60, normed=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3 points) KS investigation (with negative weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download \n",
    "\n",
    "* `check_agreement.csv`, \n",
    "* `training.csv`\n",
    "\n",
    "to the folder `datasets/` from https://www.kaggle.com/c/flavours-of-physics/data\n",
    "\n",
    "`check_agreement.csv` is a control channel, where 1-label corresponds to MC, 0-label - real data, `weight` - sPlot weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_agreement = pandas.read_csv('datasets/check_agreement.csv')\n",
    "features_for_ks = ['LifeTime', 'FlightDistance', 'IPSig', 'SPDhits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature in features_for_ks:\n",
    "    hist(data_agreement[data_agreement.signal == 1][feature].values, label='MC', **hist_kw)\n",
    "    hist(data_agreement[data_agreement.signal == 0][feature].values, label='real', **hist_kw)\n",
    "    legend()\n",
    "    title(feature)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how sPlot weights change real data pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the same histograms with sPlot weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write KS for weights pdfs\n",
    "standard function doesn't support weights :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "def compute_ks(pdf1, pdf2, weights1=None, weights2=None):\n",
    "    # Write KS metric between two weighted pdfs (see slides)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS metric pdf generation\n",
    "\n",
    "There are several things to know before doing it:\n",
    "\n",
    "* we cannot produce two samples from the same distribution with the weights, thus if we generate two samples from uniform and then compute weighted ks metric, obtained value will be greater than it is. That is why during testing hypothesis the probability of error type I will be greater than it is really (Our KS pdf will give the upper estimation of probability to reject H0, when it is true)\n",
    "\n",
    "* the second sample contains signal and background, which are sampled from different distributions.  \n",
    "In the second sample we need to generate not only signal (from the same distribution), but also bck from any distribution. But if we remember about sPlot weights property (they compensate bck) then we can conclude that generated bck could be compensated in sample using weights. Of course, some fluctuations can arise (maybe we should somehow estimate them)!\n",
    "\n",
    "* in the first approximation we can generate two samples as before\n",
    "\n",
    "### TODO\n",
    "\n",
    "* Check that for unweighted samples KS will be lower than for weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finish the function\n",
    "def generate_ks_pdf(n1, n2, w1=None, w2=None, points=3000):\n",
    "    ks = []\n",
    "    # for each point \n",
    "    for step in range(points):\n",
    "        # generate pdf1 and pdf2 from the same distributions\n",
    "        ...\n",
    "        # compute ks for generated pdfs\n",
    "        ...\n",
    "    return numpy.array(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n1 = numpy.sum(data_agreement.signal == 0)\n",
    "n2 = numpy.sum(data_agreement.signal == 1)\n",
    "w1 = data_agreement[data_agreement.signal == 0]['weight'].values\n",
    "w2 = data_agreement[data_agreement.signal == 1]['weight'].values\n",
    "ks_pdf = generate_ks_pdf(n1, n2)\n",
    "ks_pdf_weight = generate_ks_pdf(n1, n2, w1=w1, w2=w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(ks_pdf, label='simple', **hist_kw)\n",
    "hist(ks_pdf_weight, label='weight', **hist_kw)\n",
    "legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "What features have least disagreement among `features_for_ks`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3 points) Agreement restriction on the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How more disagreement features can influence the predictions agreement and classifier's quality?\n",
    "\n",
    "Do for this:\n",
    "\n",
    "* train any ensemble model on all features\n",
    "* remove `SPDhits` from training\n",
    "\n",
    "In the competition your ks metric should be less than **0.09**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv('datasets/training.csv')\n",
    "train_features = list(set(data_agreement.columns) - {'id', 'signal', 'weight'})\n",
    "train_features_wo_spd = list(set(data_agreement.columns) - {'id', 'signal', 'weight', 'SPDhits'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide train on train, test\n",
    "train_index, test_index = train_test_split(range(len(data)))\n",
    "train = data.iloc[train_index, :]\n",
    "test = data.iloc[test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to test model on ks and calculate quality\n",
    "def test_model(model, features):\n",
    "    probs = model.predict_proba(data_agreement[features])[:, 1]\n",
    "    pdf1 = probs[data_agreement.signal.values == 0]\n",
    "    pdf2 = probs[data_agreement.signal.values == 1]\n",
    "    model_agr = compute_ks(pdf1, pdf2, weights1=w1, weights2=w2)\n",
    "    print 'Agreement', model_agr, model_agr < 0.09\n",
    "    print 'AUC', roc_auc_score(test.signal.values, model.predict_proba(test[features])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does subsample parameter influence the agreement and the quality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does learning rate influence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize:\n",
    "\n",
    "* The simple solution to improve an agreement is to remove too disagreement features from the training. \n",
    "* There are exist smart solutions which will be study on the next seminars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (8 points) Analysis circle \n",
    "\n",
    "This exercise will be used at reproducible reserach seminar, thus you necessary should do it.\n",
    "\n",
    "TODO\n",
    "* train classifier to discriminate signal and background\n",
    "* predict control channel (`check_agreement.csv`)\n",
    "* intoduce correction factor $\\alpha(threshold)$ for signal efficiency in signal channel using cotrol channel\n",
    "* optimize threhsold choice maximizing $\\alpha^2 TPR^2 / FPR$ (use holdout)\n",
    "* compute corrected signal efficiency ($\\alpha * TPR$) for signal channel and background efficiency ($FPR$) for chosen threshold \n",
    "* compute efficiencies for MC signal and MC control for chosen threshold. Their difference is a systematic error on efficiency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
